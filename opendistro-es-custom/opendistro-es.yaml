# Copyright 2019 Viasat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License").
# You may not use this file except in compliance with the License.
# A copy of the License is located at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# or in the "license" file accompanying this file. This file is distributed
# on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
# express or implied. See the License for the specific language governing
# permissions and limitations under the License.

global:
  clusterName: elasticsearch

  psp:
    create: true

  rbac:
    enabled: true

  # Optionally override the docker registry to use for images
  registry: docker.io

  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  # imagePullSecrets:
  #   - myRegistryKeySecretName


elasticsearch:
  ## Used when deploying hot/warm architecture. Allows second aliased deployment to find cluster.
  ## Default {{ template opendistro-es.fullname }}-discovery.
  discoveryOverride: ""
  securityConfig:
    enabled: true
    path: "/usr/share/elasticsearch/plugins/opendistro_security/securityconfig"
    actionGroupsSecret:
    configSecret:
    internalUsersSecret:
    rolesSecret:
    rolesMappingSecret:
    tenantsSecret:
    # actionGroupsSecret: "action-groups-config"
    # configSecret: "security-config"
    # internalUsersSecret: "internal-users-config"
    # rolesSecret: "roles-config"
    # rolesMappingSecret: "roles-mapping-config"
    # tenantsSecret: "tenants-config"
    #The following option simplifies securityConfig by using a single secret and specifying the respective secrets in the corresponding files instead of creating different secrets for config,internal users, roles, roles mapping and tenants
    #Note that this is an alternative to the above secrets and shouldn't be used if the above secrets are used
    config:
       securityConfigSecret:
       data: {}
        # config.yml: |-
        # internal_users.yml: |-
        # roles.yml: |-
        # rolesMapping.yml: |-
        # tenants.yml: |-

  extraEnvs: []

  extraInitContainers: []
  # - name: do-something
  #   image: busybox
  #   command: ['do', 'something']

  extraVolumes: []
  # extraVolumes:
  # - name: elasticsearch-transport-certs
  #   secret:
  #     secretName: elasticsearch-transport-certs
  #     items:
  #     - key: tls.crt
  #       path: elk-transport-crt.pem
  #     - key: tls.key
  #       path: elk-transport-key.pem
  #     - key: ca.crt
  #       path: elk-transport-root-ca.pem
  # - name: elasticsearch-rest-certs
  #   secret:
  #     secretName: elasticsearch-rest-certs
  #     items:
  #     - key: tls.crt
  #       path: elk-rest-crt.pem
  #     - key: tls.key
  #       path: elk-rest-key.pem
  #     - key: ca.crt
  #       path: elk-rest-root-ca.pem
  # - name: elasticsearch-admin-certs
  #   secret:
  #     secretName: elasticsearch-admin-certs
  #     items:
  #     - key: tls.crt
  #       path: admin-crt.pem
  #     - key: tls.key
  #       path: admin-key.pem
  #     - key: ca.crt
  #       path: admin-root-ca.pem

  extraVolumeMounts: []
  # extraVolumeMounts:
  # - name: elasticsearch-transport-certs
  #   mountPath: /usr/share/elasticsearch/config
  #   readOnly: true
  # - name: elasticsearch-rest-certs
  #   mountPath: /usr/share/elasticsearch/config
  #   readOnly: true
  # - name: elasticsearch-admin-certs
  #   mountPath: /usr/share/elasticsearch/config
  #   readOnly: true

  initContainer:
    image: busybox
    imageTag: 1.27.2

  ## Set optimal sysctl's. This requires privilege. Can be disabled if
  ## the system has already been preconfigured.
  sysctl:
    enabled: true

  ssl:
    ## TLS is mandatory for the transport layer and can not be disabled
    transport:
      existingCertSecret: elasticsearch-transport-certs
      existingCertSecretCertSubPath: tls.crt  # elk-transport-crt.pem
      existingCertSecretKeySubPath: tls.key   # elk-transport-key.pem
      existingCertSecretRootCASubPath: ca.crt # elk-transport-root-ca.pem
    rest:
      enabled: true
      existingCertSecret: elasticsearch-rest-certs
      existingCertSecretCertSubPath: tls.crt  # elk-rest-crt.pem
      existingCertSecretKeySubPath: tls.key   # elk-rest-key.pem
      existingCertSecretRootCASubPath: ca.crt # elk-rest-root-ca.pem
    admin:
      enabled: true
      existingCertSecret: elasticsearch-admin-certs
      existingCertSecretCertSubPath: tls.crt  # admin-crt.pem
      existingCertSecretKeySubPath: tls.key   # admin-key.pem
      existingCertSecretRootCASubPath: ca.crt # admin-root-ca.pem

  config:
    cluster:
      name: ${cluster.name}
    node:
      master: ${node.master}
      data: ${node.data}
      name: ${node.name}
      ingest: ${node.ingest}
      max_local_storage_nodes: 3
      attr.box_type: hot

    processors: ${PROCESSORS:1}

    network.host: ${network.host} # 0.0.0.0 # ${NETWORK_HOST}

    # Unknown setting for v1.13: thread_pool.bulk.queue_size
    # log: java.lang.IllegalArgumentException: unknown setting [thread_pool.bulk.queue_size] did you mean any of [thread_pool.get.queue_size, thread_pool.write.queue_size, thread_pool.analyze.queue_size, thread_pool.search.queue_size, thread_pool.listener.queue_size]?
    # thread_pool:
    #   get.queue_size:
    #   analyze.queue_size:
    #   search.que_size:
    #   listener.queue_size:

    # discovery:
    #   zen:
    #     ping.unicast.hosts: ${DISCOVERY_SERVICE}
    #     minimum_master_nodes: ${NUMBER_OF_MASTERS}

    # TLS Configuration Transport Layer
    opendistro_security.ssl.transport.pemcert_filepath: elk-transport-crt.pem
    opendistro_security.ssl.transport.pemkey_filepath: elk-transport-key.pem
    opendistro_security.ssl.transport.pemtrustedcas_filepath: elk-transport-root-ca.pem
    opendistro_security.ssl.transport.enforce_hostname_verification: false
    # opendistro_security.ssl.transport.truststore_filepath: opendistro-es.truststore

    # TLS Configuration REST Layer
    opendistro_security.ssl.http.enabled: true
    opendistro_security.ssl.http.pemcert_filepath: elk-rest-crt.pem
    opendistro_security.ssl.http.pemkey_filepath: elk-rest-key.pem
    opendistro_security.ssl.http.pemtrustedcas_filepath: elk-rest-root-ca.pem

    opendistro_security.allow_unsafe_democertificates: false
    opendistro_security.allow_default_init_securityindex: true

    # See https://opendistro.github.io/for-elasticsearch-docs/docs/troubleshoot/tls/#validate-certificate-chain
    opendistro_security.authcz.admin_dn:
    - 'CN=elasticsearch.svc.cluster.local,OU=example unit,O=example org.,C=KR'
    - 'CN=*.elasticsearch'
    - 'CN=*.elasticsearch.svc'
    - 'CN=*.svc.cluster.local'
    - 'CN=elasticsearch-opendistro-es-client-service'
    - 'CN=elasticsearch-opendistro-es-data-svc'
    - 'CN=elasticsearch-opendistro-es-discovery'
    - 'CN=elasticsearch-opendistro-es-kibana-svc'
    - 'CN=*.example.com'
    - 'CN=*.example.com,OU=example unit,O=example org.,C=KR'
    - 'CN=odfe-cluster*'
    - 'CN=elasticsearch*'
    - '/CN=.*regex/'
    opendistro_security.nodes_dn:
    - 'CN=*.elasticsearch.svc.cluster.local,OU=example unit,O=example org.,C=KR'
    - 'CN=*.elasticsearch'
    - 'CN=*.elasticsearch.svc'
    - 'CN=*.svc.cluster.local'
    - 'CN=elasticsearch-opendistro-es-client-service'
    - 'CN=elasticsearch-opendistro-es-data-svc'
    - 'CN=elasticsearch-opendistro-es-discovery'
    - 'CN=elasticsearch-opendistro-es-kibana-svc'
    - 'CN=*.example.com'
    - 'CN=*.example.com,OU=example unit,O=example org.,C=KR'
    - 'CN=odfe-cluster*'
    - 'CN=elasticsearch*'
    - '/CN=.*regex/'

    opendistro_security.enable_snapshot_restore_privilege: true
    opendistro_security.check_snapshot_restore_write_privileges: true
    opendistro_security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]
    opendistro_security.system_indices.enabled: true
    opendistro_security.system_indices.indices: [".opendistro-alerting-config", ".opendistro-alerting-alert*", ".opendistro-anomaly-results*", ".opendistro-anomaly-detector*", ".opendistro-anomaly-checkpoints", ".opendistro-anomaly-detection-state", ".opendistro-reports-*", ".opendistro-notifications-*", ".opendistro-notebooks", ".opendistro-asynchronous-search-response*"]
    cluster.routing.allocation.disk.threshold_enabled: false
    
    # See https://opendistro.github.io/for-elasticsearch-docs/docs/security/audit-logs/storage-types/
    opendistro_security.audit.type: internal_elasticsearch
    opendistro_security.audit.config.disabled_rest_categories: NONE
    opendistro_security.audit.config.disabled_transport_categories: NONE

    http:
      # enabled: true # ${HTTP_ENABLE}
      compression: true

    path:
      data: /usr/share/elasticsearch/data
      logs: /usr/share/elasticsearch/logs

  configDirectory: /usr/share/elasticsearch/config

  serviceAccount:
    ## Specifies whether a ServiceAccount should be created
    create: true
    ## The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the fullname template
    # name: 
    name: opendistro  # -> opendistro-es

  transportKeyPassphrase:
    enabled: false
    passPhrase:

  sslKeyPassphrase:
    enabled: false
    passPhrase:

  master:
    enabled: true
    replicas: 1
    updateStrategy: "RollingUpdate"

    ## Enable persistence using Persistent Volume Claims
    ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      enabled: true
      ## A manually managed Persistent Volume and Claim
      ## Requires persistence.enabled: true
      ## If defined, PVC must be created manually before volume will be bound
      ##
      # existingClaim:

      ## The subdirectory of the volume to mount to, useful in dev environments
      ## and one PV for multiple services.
      ##
      subPath: ""

      ## Open Distro master Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      # storageClass: "-"
      accessModes:
        - ReadWriteOnce
      size: 8Gi
      annotations: {}

    resources: {}
    #  limits:
    #    cpu: 1
    #    memory: 1024Mi
    #  requests:
    #    cpu: 200m
    #    memory: 1024Mi
    javaOpts: "-Xms512m -Xmx512m"
    podDisruptionBudget:
      enabled: false
      minAvailable: 1
    readinessProbe: []
    livenessProbe:
      tcpSocket:
        port: transport
      initialDelaySeconds: 60
      periodSeconds: 10
    startupProbe: []
    nodeSelector: {}
    tolerations: []
    ## Anti-affinity to disallow deploying client and master nodes on the same worker node
    affinity: {}
    #  podAntiAffinity:
    #    requiredDuringSchedulingIgnoredDuringExecution:
    #      - topologyKey: "kubernetes.io/hostname"
    #        labelSelector:
    #          matchLabels:
    #            role: master
    podAnnotations: {}

    extraInitContainers: []
    # - name: do-something
    #   image: busybox
    #   command: ['do', 'something']

    extraContainers: []
    # - name: do-something
    #   image: busybox
    #   command: ['do', 'something']

  data:
    enabled: true
    ## Enables dedicated statefulset for data. Otherwise master nodes as data storage
    dedicatedPod:
      enabled: true
    replicas: 1
    updateStrategy: "RollingUpdate"

    ## Enable persistence using Persistent Volume Claims
    ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      enabled: true
      ## A manually managed Persistent Volume and Claim
      ## Requires persistence.enabled: true
      ## If defined, PVC must be created manually before volume will be bound
      ##
      # existingClaim:

      ## The subdirectory of the volume to mount to, useful in dev environments
      ## and one PV for multiple services.
      ##
      subPath: ""

      ## Open Distro master Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      # storageClass: "-"
      accessModes:
        - ReadWriteOnce
      size: 8Gi
      annotations: {}

    resources: {}
    #  limits:
    #    cpu: 1
    #    memory: 1024Mi
    #  requests:
    #    cpu: 200m
    #    memory: 1024Mi
    javaOpts: "-Xms512m -Xmx512m"
    podDisruptionBudget:
      enabled: false
      minAvailable: 1
    readinessProbe: []
    livenessProbe:
      tcpSocket:
        port: transport
      initialDelaySeconds: 60
      periodSeconds: 10
    startupProbe: []
    nodeSelector: {}
    tolerations: []
    ## Anti-affinity to disallow deploying client and master nodes on the same worker node
    affinity: {}
    #  podAntiAffinity:
    #    preferredDuringSchedulingIgnoredDuringExecution:
    #      - weight: 1
    #        podAffinityTerm:
    #          topologyKey: "kubernetes.io/hostname"
    #          labelSelector:
    #            matchLabels:
    #              role: data
    podAnnotations: {}

  client:
    enabled: true
    ## Enables dedicated deployment for client/ingest. Otherwise master nodes as client/ingest
    dedicatedPod:
      enabled: true
    service:
      type: ClusterIP
      annotations: {}
        # # Defined ELB backend protocol as HTTPS to allow connection to Elasticsearch API
        # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: https

        # # ARN of ACM certificate registered to the deployed ELB for handling connections over TLS
        # # ACM certificate should be issued to the DNS hostname defined earlier (elk.sec.example.com)
        # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: "arn:aws:acm:us-east-1:111222333444:certificate/c69f6022-b24f-43d9-b9c8-dfe288d9443d"
        # service.beta.kubernetes.io/aws-load-balancer-ssl-ports: "https"

        # service.beta.kubernetes.io/aws-load-balancer-connection-draining-enabled: "true"
        # service.beta.kubernetes.io/aws-load-balancer-connection-draining-timeout: "60"
        # service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"

        # # Annotation to create internal only ELB
        # service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0
    replicas: 1
    javaOpts: "-Xms512m -Xmx512m"
    ingress:
      ## Set to true to enable ingress record generation
      enabled: false
      annotations: {}
      #  kubernetes.io/ingress.class: nginx
      #  kubernetes.io/tls-acme: "true"
      #  # Depending on your Ingress Controller you may need to set one of the two below annotations to have NGINX call the backend using HTTPS
      #  nginx.org/ssl-services:"{{ template "opendistro-es.fullname" . }}-client-service"
      #  nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      labels: {}
      path: /
      hosts:
        - chart-example.local
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.local
    resources: {}
    #  limits:
    #    cpu: 1
    #    memory: 1024Mi
    #  requests:
    #    cpu: 200m
    #    memory: 1024Mi
    podDisruptionBudget:
      enabled: false
      minAvailable: 1
    readinessProbe: []
    livenessProbe:
      tcpSocket:
        port: transport
      initialDelaySeconds: 60
      periodSeconds: 10
    startupProbe: []
    nodeSelector: {}
    tolerations: []
    ## Weighted anti-affinity to disallow deploying client node to the same worker node as master node
    affinity: {}
    #  podAntiAffinity:
    #    preferredDuringSchedulingIgnoredDuringExecution:
    #      - weight: 1
    #        podAffinityTerm:
    #          topologyKey: "kubernetes.io/hostname"
    #          labelSelector:
    #            matchLabels:
    #              role: client
    podAnnotations: {}

  log4jConfig: ""

  loggingConfig:
    ## Default config
    ## you can override this using by setting a system property, for example -Des.logger.level=DEBUG
    es.logger.level: INFO
    rootLogger: ${es.logger.level}, console
    logger:
      ## log action execution errors for easier debugging
      action: DEBUG
      ## reduce the logging for aws, too much is logged under the default INFO
      com.amazonaws: WARN
    appender:
      console:
        type: console
        layout:
          type: consolePattern
          conversionPattern: "[%d{ISO8601}][%-5p][%-25c] %m%n"

  maxMapCount: 262144

  image: amazon/opendistro-for-elasticsearch
  imageTag: 1.13.0
  ## Specifies the image pull policy. Can be "Always" or "IfNotPresent" or "Never".
  ## Default to "Always".
  imagePullPolicy: ""


nameOverride: ""
fullnameOverride: ""
